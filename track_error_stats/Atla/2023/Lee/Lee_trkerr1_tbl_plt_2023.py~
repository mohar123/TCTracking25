import netCDF4 as nc4
import matplotlib.pyplot as plt
import numpy as np
import numpy.ma as ma
import matplotlib.dates as mdates
from scipy.spatial import distance
from mpl_toolkits.basemap import Basemap
from matplotlib.dates import DayLocator, HourLocator, DateFormatter, drange
from numpy import arange

import pandas as pd
import glob,os
import sys
import csv
import xarray as xr
import cartopy.crs       as     ccrs
import cartopy.feature   as     cfeature
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER

# to create ncdf4 files need the following tools
import datetime  # Python standard library datetime  module
import time
from netCDF4 import Dataset,num2date, date2num  # http://code.google.com/p/netcdf4-python/

#---
# calculate track error
from math import radians, cos, sin, asin, sqrt
def distance(lat1, lat2, lon1, lon2):

    # The math module contains a function named
    # radians which converts from degrees to radians.
    lon1 = radians(lon1)
    lon2 = radians(lon2)
    lat1 = radians(lat1)
    lat2 = radians(lat2)

    # Haversine formula
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2

    c = 2 * asin(sqrt(a))

 # Radius of earth in kilometers. Use 3956 for miles
    r = 6371

    # calculate the result
    return(c * r)

#############TC - 
#---
#ONE
#___

# Obtain the date/time and initial lat/lon from command line:
dirm = "/home/gmao_ops/f5295_fp/run/.../archive/forecast/Y2023/M09/D06/H00/"
col = "GEOS.fp.fcst.inst3_3d_asm_Np.20230906_00+"
beg_date = datetime.datetime(year=2023, month=9, day=6, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=11, hour=0)

delta_date = datetime.timedelta(hours=6)

list_files = list()
list_fileso = list()

cur_date = beg_date

while cur_date < end_date:
    file = cur_date.strftime(dirm+col+"%Y%m%d_%H%M.V01.nc4")
    list_files.append(file)
    cur_date += delta_date

print(list_files)
lon_all, lat_all, slp_min_all, tim_all, fcst_all = [], [], [], [], []
del_lat = 3.0
del_lon = 3.0
lat_slice1 = 13.
lat_slice2 = 23. 
lon_slice1 = -72.
lon_slice2 = -42.

for file in list_files:
    with xr.open_dataset(file, engine='netcdf4') as f:  
        
        slp_1 = f.SLP.sel(lat=slice(lat_slice1,lat_slice2),lon=slice(lon_slice1,lon_slice2))
        slp_1_min = float(slp_1.min())*0.01
        loc1 = np.where(slp_1[0,:,:] == np.amin(slp_1[0,:,:]))
        lat1 = float(slp_1.lat[loc1[0]].values)
        lon1 = float(slp_1.lon[loc1[1]].values)
        tim1 = (slp_1.time.values) 

# tim1 is a yyyymmdd(64bit data)
        ds = str(tim1[0]).partition('T')[0].split('-')
# when in doubt about the data type always print(type(varname)) 
        #print(ds,type(ds))

        time_str = str(tim1[0]).partition('T')[2][0:2]
# when in doubt about the data type always print(type(varname)) 
        #print(time_str,type(time_str))

        ds.append(time_str)

        d = datetime.datetime(int(ds[0]), int(ds[1]), int(ds[2]), int(ds[3]))
        ds1 = d.strftime("%Y%m%d%H")
        fcst_diff1 = (d-beg_date).total_seconds() / 3600
#list if lat >=dely ....
        
        if lat_all:
           if (lat1 <= lat_all[-1]+del_lat) and (lat1 >= lat_all[-1]-del_lat) and \
              (lon1 <= lon_all[-1]+del_lon) and (lon1 >= lon_all[-1]-del_lon):
              lat_all.append(lat1)
              slp_min_all.append(slp_1_min)
              lon_all.append(lon1)
              tim_all.append(ds1)
              fcst_all.append(fcst_diff1)
        else:
            slp_min_all.append(slp_1_min)
            lon_all.append(lon1)
            lat_all.append(lat1)
            tim_all.append(ds1)
            fcst_all.append(fcst_diff1)
        
#print(tim_all,lat_all,lon_all,slp_min_all)
df1 = pd.DataFrame((zip(tim_all,lat_all,lon_all,slp_min_all,fcst_all)), columns = ['c1','c2','c3','c4','c5'])
print(df1)
#sys.exit()
#------------------------------
#---
#TWO
#___
# Obtain the date/time and initial lat/lon from command line:
dirm = "/home/gmao_ops/f5295_fp/run/.../archive/forecast/Y2023/M09/D07/H00/"
col = "GEOS.fp.fcst.inst3_3d_asm_Np.20230907_00+"
beg_date = datetime.datetime(year=2023, month=9, day=7, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=12, hour=0)

delta_date = datetime.timedelta(hours=6)

list_files = list()
list_fileso = list()

cur_date = beg_date

while cur_date < end_date:
    file = cur_date.strftime(dirm+col+"%Y%m%d_%H%M.V01.nc4")
    list_files.append(file)
    cur_date += delta_date

print(list_files)
lon_all1, lat_all1, slp_min_all1, tim_all1, fcst_all1 = [], [], [], [], []
del_lat = 3.0
del_lon = 3.
lat_slice1 = 14.5
lat_slice2 = 24.
lon_slice1 = -72.
lon_slice2 = -46.
for file in list_files:
    with xr.open_dataset(file, engine='netcdf4') as f:  
        
        slp_1 = f.SLP.sel(lat=slice(lat_slice1,lat_slice2),lon=slice(lon_slice1,lon_slice2))
        slp_1_min = float(slp_1.min())*0.01
        loc1 = np.where(slp_1[0,:,:] == np.amin(slp_1[0,:,:]))
        lat1 = float(slp_1.lat[loc1[0][0]].values)
        lon1 = float(slp_1.lon[loc1[1][0]].values)
        tim1 = (slp_1.time.values) 

# tim1 is a yyyymmdd(64bit data)
        ds = str(tim1[0]).partition('T')[0].split('-')
# when in doubt about the data type always print(type(varname)) 
        #print(ds,type(ds))

        time_str = str(tim1[0]).partition('T')[2][0:2]
# when in doubt about the data type always print(type(varname)) 
        #print(time_str,type(time_str))

        ds.append(time_str)

        d = datetime.datetime(int(ds[0]), int(ds[1]), int(ds[2]), int(ds[3]))
        ds1 = d.strftime("%Y%m%d%H")
        fcst_diff1 = (d-beg_date).total_seconds() / 3600
#list if lat >=dely ....

        if lat_all1:
           if (lat1 <= lat_all1[-1]+del_lat) and (lat1 >= lat_all1[-1]-del_lat) and \
              (lon1 <= lon_all1[-1]+del_lon) and (lon1 >= lon_all1[-1]-del_lon):
              lat_all1.append(lat1)
              slp_min_all1.append(slp_1_min)
              lon_all1.append(lon1)
              tim_all1.append(ds1)
              fcst_all1.append(fcst_diff1)
        else:
            slp_min_all1.append(slp_1_min)
            lon_all1.append(lon1)
            lat_all1.append(lat1)
            tim_all1.append(ds1)
            fcst_all1.append(fcst_diff1)

#print(tim_all,lat_all,lon_all,slp_min_all)
df2 = pd.DataFrame((zip(tim_all1,lat_all1,lon_all1,slp_min_all1,fcst_all1)), columns = ['c1','c2','c3','c4','c5'])
print(df2)
#sys.exit()
#------------------------------
#---
#THREE
#___
# Obtain the date/time and initial lat/lon from command line:
dirm = "/home/gmao_ops/f5295_fp/run/.../archive/forecast/Y2023/M09/D08/H00/"
col = "GEOS.fp.fcst.inst3_3d_asm_Np.20230908_00+"
beg_date = datetime.datetime(year=2023, month=9, day=8, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=12, hour=0)

delta_date = datetime.timedelta(hours=6)

list_files = list()
list_fileso = list()

cur_date = beg_date

while cur_date < end_date:
    file = cur_date.strftime(dirm+col+"%Y%m%d_%H%M.V01.nc4")
    list_files.append(file)
    cur_date += delta_date

print(list_files)
lon_all2, lat_all2, slp_min_all2, tim_all2, fcst_all2 = [], [], [], [], []
del_lat = 3.0
del_lon = 3.0
lat_slice1 = 16
lat_slice2 = 28.
lon_slice1 = -70
lon_slice2 = -50
for file in list_files:
    with xr.open_dataset(file, engine='netcdf4') as f:  
        
        slp_1 = f.SLP.sel(lat=slice(lat_slice1,lat_slice2),lon=slice(lon_slice1,lon_slice2))
        slp_1_min = float(slp_1.min())*0.01
        loc1 = np.where(slp_1[0,:,:] == np.amin(slp_1[0,:,:]))
        lat1 = float(slp_1.lat[loc1[0][0]].values)
        lon1 = float(slp_1.lon[loc1[1][0]].values)
        tim1 = (slp_1.time.values) 

# tim1 is a yyyymmdd(64bit data)
        ds = str(tim1[0]).partition('T')[0].split('-')
# when in doubt about the data type always print(type(varname)) 
        #print(ds,type(ds))

        time_str = str(tim1[0]).partition('T')[2][0:2]
# when in doubt about the data type always print(type(varname)) 
        #print(time_str,type(time_str))

        ds.append(time_str)

        d = datetime.datetime(int(ds[0]), int(ds[1]), int(ds[2]), int(ds[3]))
        ds1 = d.strftime("%Y%m%d%H")
        fcst_diff1 = (d-beg_date).total_seconds() / 3600
#list if lat >=dely ....

        if lat_all2:
           if (lat1 <= lat_all2[-1]+del_lat) and (lat1 >= lat_all2[-1]-del_lat) and \
              (lon1 <= lon_all2[-1]+del_lon) and (lon1 >= lon_all2[-1]-del_lon):
              lat_all2.append(lat1)
              slp_min_all2.append(slp_1_min)
              lon_all2.append(lon1)
              tim_all2.append(ds1)
              fcst_all2.append(fcst_diff1)
        else:
            slp_min_all2.append(slp_1_min)
            lon_all2.append(lon1)
            lat_all2.append(lat1)
            tim_all2.append(ds1)
            fcst_all2.append(fcst_diff1)

#print(tim_all,lat_all,lon_all,slp_min_all)
df3 = pd.DataFrame((zip(tim_all2,lat_all2,lon_all2,slp_min_all2,fcst_all2)), columns = ['c1','c2','c3','c4','c5'])
print(df3)
#sys.exit()
#------------------------------
#---
#FOUR
#___
# Obtain the date/time and initial lat/lon from command line:
dirm = "/home/gmao_ops/f5295_fp/run/.../archive/forecast/Y2023/M09/D09/H00/"
col = "GEOS.fp.fcst.inst3_3d_asm_Np.20230909_00+"
beg_date = datetime.datetime(year=2023, month=9, day=9, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=13, hour=0)

delta_date = datetime.timedelta(hours=6)

list_files = list()
list_fileso = list()

cur_date = beg_date

while cur_date < end_date:
    file = cur_date.strftime(dirm+col+"%Y%m%d_%H%M.V01.nc4")
    list_files.append(file)
    cur_date += delta_date

print(list_files)
lon_all3, lat_all3, slp_min_all3, tim_all3, fcst_all3 = [], [], [], [], []
del_lat = 3.0
del_lon = 3.0
lat_slice1 = 18.
lat_slice2 = 26.
lon_slice1 = -67.
lon_slice2 = -50.
for file in list_files:
    with xr.open_dataset(file, engine='netcdf4') as f:  
        
        slp_1 = f.SLP.sel(lat=slice(lat_slice1,lat_slice2),lon=slice(lon_slice1,lon_slice2))
        slp_1_min = float(slp_1.min())*0.01
        loc1 = np.where(slp_1[0,:,:] == np.amin(slp_1[0,:,:]))
        lat1 = float(slp_1.lat[loc1[0][0]].values)
        lon1 = float(slp_1.lon[loc1[1][0]].values)
        tim1 = (slp_1.time.values) 

# tim1 is a yyyymmdd(64bit data)
        ds = str(tim1[0]).partition('T')[0].split('-')
# when in doubt about the data type always print(type(varname)) 
        #print(ds,type(ds))

        time_str = str(tim1[0]).partition('T')[2][0:2]
# when in doubt about the data type always print(type(varname)) 
        #print(time_str,type(time_str))

        ds.append(time_str)

        d = datetime.datetime(int(ds[0]), int(ds[1]), int(ds[2]), int(ds[3]))
        ds1 = d.strftime("%Y%m%d%H")
        fcst_diff1 = (d-beg_date).total_seconds() / 3600
#list if lat >=dely ....

        if lat_all3:
           if (lat1 <= lat_all3[-1]+del_lat) and (lat1 >= lat_all3[-1]-del_lat) and \
              (lon1 <= lon_all3[-1]+del_lon) and (lon1 >= lon_all3[-1]-del_lon):
              lat_all3.append(lat1)
              slp_min_all3.append(slp_1_min)
              lon_all3.append(lon1)
              tim_all3.append(ds1)
              fcst_all3.append(fcst_diff1)
        else:
            slp_min_all3.append(slp_1_min)
            lon_all3.append(lon1)
            lat_all3.append(lat1)
            tim_all3.append(ds1)
            fcst_all3.append(fcst_diff1)

#print(tim_all,lat_all,lon_all,slp_min_all)
df4 = pd.DataFrame((zip(tim_all3,lat_all3,lon_all3,slp_min_all3,fcst_all3)), columns = ['c1','c2','c3','c4','c5'])
print(df4)
#sys.exit()
#---
#FIVE
#___
# Obtain the date/time and initial lat/lon from command line:
dirm = "/home/gmao_ops/f5295_fp/run/.../archive/forecast/Y2023/M09/D10/H00/"
col = "GEOS.fp.fcst.inst3_3d_asm_Np.20230910_00+"
beg_date = datetime.datetime(year=2023, month=9, day=10, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=14, hour=0)

delta_date = datetime.timedelta(hours=6)

list_files = list()
list_fileso = list()

cur_date = beg_date

while cur_date < end_date:
    file = cur_date.strftime(dirm+col+"%Y%m%d_%H%M.V01.nc4")
    list_files.append(file)
    cur_date += delta_date

print(list_files)
lon_all4, lat_all4, slp_min_all4, tim_all4, fcst_all4 = [], [], [], [], []
del_lat = 3.0
del_lon = 3.0
lat_slice1 = 19.
lat_slice2 = 29.
lon_slice1 = -70.
lon_slice2 = -50.
for file in list_files:
    with xr.open_dataset(file, engine='netcdf4') as f:  
        
        slp_1 = f.SLP.sel(lat=slice(lat_slice1,lat_slice2),lon=slice(lon_slice1,lon_slice2))
        slp_1_min = float(slp_1.min())*0.01
        loc1 = np.where(slp_1[0,:,:] == np.amin(slp_1[0,:,:]))
        lat1 = float(slp_1.lat[loc1[0][0]].values)
        lon1 = float(slp_1.lon[loc1[1][0]].values)
        tim1 = (slp_1.time.values) 

# tim1 is a yyyymmdd(64bit data)
        ds = str(tim1[0]).partition('T')[0].split('-')
# when in doubt about the data type always print(type(varname)) 
        #print(ds,type(ds))

        time_str = str(tim1[0]).partition('T')[2][0:2]
# when in doubt about the data type always print(type(varname)) 
        #print(time_str,type(time_str))

        ds.append(time_str)

        d = datetime.datetime(int(ds[0]), int(ds[1]), int(ds[2]), int(ds[3]))
        ds1 = d.strftime("%Y%m%d%H")
        fcst_diff1 = (d-beg_date).total_seconds() / 3600
#list if lat >=dely ....

        if lat_all4:
           if (lat1 <= lat_all4[-1]+del_lat) and (lat1 >= lat_all4[-1]-del_lat) and \
              (lon1 <= lon_all4[-1]+del_lon) and (lon1 >= lon_all4[-1]-del_lon):
              lat_all4.append(lat1)
              slp_min_all4.append(slp_1_min)
              lon_all4.append(lon1)
              tim_all4.append(ds1)
              fcst_all4.append(fcst_diff1)
        else:
            slp_min_all4.append(slp_1_min)
            lon_all4.append(lon1)
            lat_all4.append(lat1)
            tim_all4.append(ds1)
            fcst_all4.append(fcst_diff1)

#print(tim_all,lat_all,lon_all,slp_min_all)
df5 = pd.DataFrame((zip(tim_all4,lat_all4,lon_all4,slp_min_all4,fcst_all4)), columns = ['c1','c2','c3','c4','c5'])
print(df5)

#---
#SIX
#___
# Obtain the date/time and initial lat/lon from command line:
dirm = "/home/gmao_ops/f5295_fp/run/.../archive/forecast/Y2023/M09/D11/H00/"
col = "GEOS.fp.fcst.inst3_3d_asm_Np.20230911_00+"
beg_date = datetime.datetime(year=2023, month=9, day=11, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=15, hour=0)

delta_date = datetime.timedelta(hours=6)

list_files = list()
list_fileso = list()

cur_date = beg_date

while cur_date < end_date:
    file = cur_date.strftime(dirm+col+"%Y%m%d_%H%M.V01.nc4")
    list_files.append(file)
    cur_date += delta_date

print(list_files)
lon_all5, lat_all5, slp_min_all5, tim_all5, fcst_all5 = [], [], [], [], []
del_lat = 3.0
del_lon = 3.0
lat_slice1 = 21.
lat_slice2 = 31.
lon_slice1 = -70.
lon_slice2 = -50.
for file in list_files:
    with xr.open_dataset(file, engine='netcdf4') as f:  
        
        slp_1 = f.SLP.sel(lat=slice(lat_slice1,lat_slice2),lon=slice(lon_slice1,lon_slice2))
        slp_1_min = float(slp_1.min())*0.01
        loc1 = np.where(slp_1[0,:,:] == np.amin(slp_1[0,:,:]))
        lat1 = float(slp_1.lat[loc1[0][0]].values)
        lon1 = float(slp_1.lon[loc1[1][0]].values)
        tim1 = (slp_1.time.values) 

# tim1 is a yyyymmdd(64bit data)
        ds = str(tim1[0]).partition('T')[0].split('-')
# when in doubt about the data type always print(type(varname)) 
        #print(ds,type(ds))

        time_str = str(tim1[0]).partition('T')[2][0:2]
# when in doubt about the data type always print(type(varname)) 
        #print(time_str,type(time_str))

        ds.append(time_str)

        d = datetime.datetime(int(ds[0]), int(ds[1]), int(ds[2]), int(ds[3]))
        ds1 = d.strftime("%Y%m%d%H")
        fcst_diff1 = (d-beg_date).total_seconds() / 3600
#list if lat >=dely ....

        if lat_all5:
           if (lat1 <= lat_all5[-1]+del_lat) and (lat1 >= lat_all5[-1]-del_lat) and \
              (lon1 <= lon_all5[-1]+del_lon) and (lon1 >= lon_all5[-1]-del_lon):
              lat_all5.append(lat1)
              slp_min_all5.append(slp_1_min)
              lon_all5.append(lon1)
              tim_all5.append(ds1)
              fcst_all5.append(fcst_diff1)
        else:
            slp_min_all5.append(slp_1_min)
            lon_all5.append(lon1)
            lat_all5.append(lat1)
            tim_all5.append(ds1)
            fcst_all5.append(fcst_diff1)

#print(tim_all,lat_all,lon_all,slp_min_all)
df6 = pd.DataFrame((zip(tim_all5,lat_all5,lon_all5,slp_min_all5,fcst_all5)), columns = ['c1','c2','c3','c4','c5'])
print(df6)

#---
#SEVEN
#___
# Obtain the date/time and initial lat/lon from command line:
dirm = "/home/gmao_ops/f5295_fp/run/.../archive/forecast/Y2023/M09/D12/H00/"
col = "GEOS.fp.fcst.inst3_3d_asm_Np.20230912_00+"
beg_date = datetime.datetime(year=2023, month=9, day=12, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=16, hour=0)

delta_date = datetime.timedelta(hours=6)

list_files = list()
list_fileso = list()

cur_date = beg_date

while cur_date < end_date:
    file = cur_date.strftime(dirm+col+"%Y%m%d_%H%M.V01.nc4")
    list_files.append(file)
    cur_date += delta_date

print(list_files)
lon_all6, lat_all6, slp_min_all6, tim_all6, fcst_all6 = [], [], [], [], []
del_lat = 3.0
del_lon = 3.0
lat_slice1 = 22.5
lat_slice2 = 35.
lon_slice1 = -72.
lon_slice2 = -60.
for file in list_files:
    with xr.open_dataset(file, engine='netcdf4') as f:  
        
        slp_1 = f.SLP.sel(lat=slice(lat_slice1,lat_slice2),lon=slice(lon_slice1,lon_slice2))
        slp_1_min = float(slp_1.min())*0.01
        loc1 = np.where(slp_1[0,:,:] == np.amin(slp_1[0,:,:]))
        lat1 = float(slp_1.lat[loc1[0][0]].values)
        lon1 = float(slp_1.lon[loc1[1][0]].values)
        tim1 = (slp_1.time.values) 

# tim1 is a yyyymmdd(64bit data)
        ds = str(tim1[0]).partition('T')[0].split('-')
# when in doubt about the data type always print(type(varname)) 
        #print(ds,type(ds))

        time_str = str(tim1[0]).partition('T')[2][0:2]
# when in doubt about the data type always print(type(varname)) 
        #print(time_str,type(time_str))

        ds.append(time_str)

        d = datetime.datetime(int(ds[0]), int(ds[1]), int(ds[2]), int(ds[3]))
        ds1 = d.strftime("%Y%m%d%H")
        fcst_diff1 = (d-beg_date).total_seconds() / 3600
#list if lat >=dely ....

        if lat_all6:
           if (lat1 <= lat_all6[-1]+del_lat) and (lat1 >= lat_all6[-1]-del_lat) and \
              (lon1 <= lon_all6[-1]+del_lon) and (lon1 >= lon_all6[-1]-del_lon):
              lat_all6.append(lat1)
              slp_min_all6.append(slp_1_min)
              lon_all6.append(lon1)
              tim_all6.append(ds1)
              fcst_all6.append(fcst_diff1)
        else:
            slp_min_all6.append(slp_1_min)
            lon_all6.append(lon1)
            lat_all6.append(lat1)
            tim_all6.append(ds1)
            fcst_all6.append(fcst_diff1)

#print(tim_all,lat_all,lon_all,slp_min_all)
df7 = pd.DataFrame((zip(tim_all6,lat_all6,lon_all6,slp_min_all6,fcst_all6)), columns = ['c1','c2','c3','c4','c5'])
print(df7)

#---
#EIGHT
#___
# Obtain the date/time and initial lat/lon from command line:
dirm = "/home/gmao_ops/f5295_fp/run/.../archive/forecast/Y2023/M09/D13/H00/"
col = "GEOS.fp.fcst.inst3_3d_asm_Np.20230913_00+"
beg_date = datetime.datetime(year=2023, month=9, day=13, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=17, hour=0)

delta_date = datetime.timedelta(hours=6)

list_files = list()
list_fileso = list()

cur_date = beg_date

while cur_date < end_date:
    file = cur_date.strftime(dirm+col+"%Y%m%d_%H%M.V01.nc4")
    list_files.append(file)
    cur_date += delta_date

print(list_files)
lon_all7, lat_all7, slp_min_all7, tim_all7, fcst_all7 = [], [], [], [], []
del_lat = 3.0
del_lon = 3.0
lat_slice1 = 24.5
lat_slice2 = 45.0
lon_slice1 = -72.
lon_slice2 = -64.
for file in list_files:
    with xr.open_dataset(file, engine='netcdf4') as f:  
        
        slp_1 = f.SLP.sel(lat=slice(lat_slice1,lat_slice2),lon=slice(lon_slice1,lon_slice2))
        slp_1_min = float(slp_1.min())*0.01
        loc1 = np.where(slp_1[0,:,:] == np.amin(slp_1[0,:,:]))
        lat1 = float(slp_1.lat[loc1[0][0]].values)
        lon1 = float(slp_1.lon[loc1[1][0]].values)
        tim1 = (slp_1.time.values) 

# tim1 is a yyyymmdd(64bit data)
        ds = str(tim1[0]).partition('T')[0].split('-')
# when in doubt about the data type always print(type(varname)) 
        #print(ds,type(ds))

        time_str = str(tim1[0]).partition('T')[2][0:2]
# when in doubt about the data type always print(type(varname)) 
        #print(time_str,type(time_str))

        ds.append(time_str)

        d = datetime.datetime(int(ds[0]), int(ds[1]), int(ds[2]), int(ds[3]))
        ds1 = d.strftime("%Y%m%d%H")
        fcst_diff1 = (d-beg_date).total_seconds() / 3600
#list if lat >=dely ....

        if lat_all7:
           if (lat1 <= lat_all7[-1]+del_lat) and (lat1 >= lat_all7[-1]-del_lat) and \
              (lon1 <= lon_all7[-1]+del_lon) and (lon1 >= lon_all7[-1]-del_lon):
              lat_all7.append(lat1)
              slp_min_all7.append(slp_1_min)
              lon_all7.append(lon1)
              tim_all7.append(ds1)
              fcst_all7.append(fcst_diff1)
        else:
            slp_min_all7.append(slp_1_min)
            lon_all7.append(lon1)
            lat_all7.append(lat1)
            tim_all7.append(ds1)
            fcst_all7.append(fcst_diff1)

#print(tim_all,lat_all,lon_all,slp_min_all)
df8 = pd.DataFrame((zip(tim_all7,lat_all7,lon_all7,slp_min_all7,fcst_all7)), columns = ['c1','c2','c3','c4','c5'])
print(df8)

#--------------------------------------------------------

diro = "/nfs3m/archive/sfa_cache08/projects/input/dao_ops/ops/flk/tcvitals/text/TCVITALS/Y2023/"
colo = ".syndata.tcvitals"

beg_date = datetime.datetime(year=2023, month=9, day=6, hour=0)
end_date = datetime.datetime(year=2023, month=9, day=14, hour=12)

delta_date = datetime.timedelta(hours=6)
cur_date = beg_date

lon_obs, lat_obs, slp_min_obs, tim_obs = [], [], [], []
while cur_date < end_date:
    print(cur_date)
    file = cur_date.strftime(diro+"M%m/gfs.%y%m%d.t%Hz"+colo)
    list_fileso.append(file)
    cur_date += delta_date
print(list_fileso)
for file in list_fileso:
    with open(file,'r') as f:
        for line in f:
            #print(line)
            cells = line.strip()
            if "LEE" in line:
                yyyymmdd = cells[19:27]
                print(yyyymmdd)
                hh = cells[28:30]
                tim = yyyymmdd+hh
                lat = cells[33:37]
                if ((lat.endswith('N'))==True):
                    lat=float(lat[0:3])*0.1
                elif ((lat.endswith('S'))==True):
                    lat=float(lat[0:3])*-0.1
                lon = cells[38:43]
                if ((lon.endswith('E'))==True):
                    lon=float(lon[0:4])*0.1
                elif ((lon.endswith('W'))==True):
                    lon=float(lon[0:4])*-0.1
                pres = float(cells[52:56]) 
            
                slp_min_obs.append(pres)
                lon_obs.append(lon)
                lat_obs.append(lat)
                tim_obs.append(tim)

#print(tim_obs,lat_obs,lon_obs,slp_min_obs)
dfo = pd.DataFrame((zip(tim_obs,lat_obs,lon_obs,slp_min_obs)), columns = ['c1','c2','c3','c4'])
print(dfo)
#sys.exit()
#----------------------------------------

idx_obs,idx_all=[],[]

trk_err_all,trk_tim_all,trk_lat_all,trk_lon_all,trk_slp_min_all,trk_fcst_all = [],[],[],[],[],[]
for idx1, val1 in enumerate(tim_obs):
  for idx2, val2 in enumerate(tim_all):
      if (tim_obs[idx1]==tim_all[idx2]):
          err=(distance(lat_all[idx2], lat_obs[idx1], lon_all[idx2], lon_obs[idx1]))*0.54
          trk_err_all.append(err)
          trk_tim_all.append(tim_all[idx2])
          trk_lat_all.append(lat_all[idx2])
          trk_lon_all.append(lon_all[idx2])
          trk_slp_min_all.append(slp_min_all[idx2])
          trk_fcst_all.append(fcst_all[idx2])
#dft1 = pd.DataFrame((zip(trk_tim_all,trk_lat_all,trk_lon_all,trk_slp_min_all,trk_err_all)), columns = ['c1','c2','c3','c4','c5'])
dft1 = pd.DataFrame((zip(trk_fcst_all,trk_err_all)), columns = ['FCST_HR','06/00Z'])
#print(dft1)

trk_err_all1,trk_tim_all1,trk_lat_all1,trk_lon_all1,trk_slp_min_all1,trk_fcst_all1 = [],[],[],[],[],[]
for idx1, val1 in enumerate(tim_obs):
  for idx2, val2 in enumerate(tim_all1):
      if (tim_obs[idx1]==tim_all1[idx2]):
          err=(distance(lat_all1[idx2], lat_obs[idx1], lon_all1[idx2], lon_obs[idx1]))*0.54
          trk_err_all1.append(err)
          trk_tim_all1.append(tim_all1[idx2])
          trk_lat_all1.append(lat_all1[idx2])
          trk_lon_all1.append(lon_all1[idx2])
          trk_slp_min_all1.append(slp_min_all1[idx2])
          trk_fcst_all1.append(fcst_all1[idx2])
dft2 = pd.DataFrame((zip(trk_fcst_all1,trk_err_all1)), columns = ['FCST_HR','07/00Z'])
#print(dft2)
#sys.exit()

trk_err_all2,trk_tim_all2,trk_lat_all2,trk_lon_all2,trk_slp_min_all2,trk_fcst_all2 = [],[],[],[],[],[]
for idx1, val1 in enumerate(tim_obs):
  for idx2, val2 in enumerate(tim_all2):
      if (tim_obs[idx1]==tim_all2[idx2]):
          err=(distance(lat_all2[idx2], lat_obs[idx1], lon_all2[idx2], lon_obs[idx1]))*0.54
          trk_err_all2.append(err)
          trk_tim_all2.append(tim_all2[idx2])
          trk_lat_all2.append(lat_all2[idx2])
          trk_lon_all2.append(lon_all2[idx2])
          trk_slp_min_all2.append(slp_min_all2[idx2])
          trk_fcst_all2.append(fcst_all2[idx2])
dft3 = pd.DataFrame((zip(trk_fcst_all2,trk_err_all2)), columns = ['FCST_HR','08/00Z'])

trk_err_all3,trk_tim_all3,trk_lat_all3,trk_lon_all3,trk_slp_min_all3,trk_fcst_all3 = [],[],[],[],[],[]
for idx1, val1 in enumerate(tim_obs):
  for idx2, val2 in enumerate(tim_all3):
      if (tim_obs[idx1]==tim_all3[idx2]):
          err=(distance(lat_all3[idx2], lat_obs[idx1], lon_all3[idx2], lon_obs[idx1]))*0.54
          trk_err_all3.append(err)
          trk_tim_all3.append(tim_all3[idx2])
          trk_lat_all3.append(lat_all3[idx2])
          trk_lon_all3.append(lon_all3[idx2])
          trk_slp_min_all3.append(slp_min_all3[idx2])
          trk_fcst_all3.append(fcst_all3[idx2])
dft4 = pd.DataFrame((zip(trk_fcst_all3,trk_err_all3)), columns = ['FCST_HR','09/00Z'])

trk_err_all4,trk_tim_all4,trk_lat_all4,trk_lon_all4,trk_slp_min_all4,trk_fcst_all4 = [],[],[],[],[],[]
for idx1, val1 in enumerate(tim_obs):
  for idx2, val2 in enumerate(tim_all4):
      if (tim_obs[idx1]==tim_all4[idx2]):
          err=(distance(lat_all4[idx2], lat_obs[idx1], lon_all4[idx2], lon_obs[idx1]))*0.54
          trk_err_all4.append(err)
          trk_tim_all4.append(tim_all4[idx2])
          trk_lat_all4.append(lat_all4[idx2])
          trk_lon_all4.append(lon_all4[idx2])
          trk_slp_min_all4.append(slp_min_all4[idx2])
          trk_fcst_all4.append(fcst_all4[idx2])
dft5 = pd.DataFrame((zip(trk_fcst_all4,trk_err_all4)), columns = ['FCST_HR','10/00Z'])

trk_err_all5,trk_tim_all5,trk_lat_all5,trk_lon_all5,trk_slp_min_all5,trk_fcst_all5 = [],[],[],[],[],[]
for idx1, val1 in enumerate(tim_obs):
  for idx2, val2 in enumerate(tim_all5):
      if (tim_obs[idx1]==tim_all5[idx2]):
          err=(distance(lat_all5[idx2], lat_obs[idx1], lon_all5[idx2], lon_obs[idx1]))*0.54
          trk_err_all5.append(err)
          trk_tim_all5.append(tim_all5[idx2])
          trk_lat_all5.append(lat_all5[idx2])
          trk_lon_all5.append(lon_all5[idx2])
          trk_slp_min_all5.append(slp_min_all5[idx2])
          trk_fcst_all5.append(fcst_all5[idx2])
dft6 = pd.DataFrame((zip(trk_fcst_all5,trk_err_all5)), columns = ['FCST_HR','11/00Z'])

trk_err_all6,trk_tim_all6,trk_lat_all6,trk_lon_all6,trk_slp_min_all6,trk_fcst_all6 = [],[],[],[],[],[]
for idx1, val1 in enumerate(tim_obs):
  for idx2, val2 in enumerate(tim_all6):
      if (tim_obs[idx1]==tim_all6[idx2]):
          err=(distance(lat_all6[idx2], lat_obs[idx1], lon_all6[idx2], lon_obs[idx1]))*0.54
          trk_err_all6.append(err)
          trk_tim_all6.append(tim_all6[idx2])
          trk_lat_all6.append(lat_all6[idx2])
          trk_lon_all6.append(lon_all6[idx2])
          trk_slp_min_all6.append(slp_min_all6[idx2])
          trk_fcst_all6.append(fcst_all6[idx2])
dft7 = pd.DataFrame((zip(trk_fcst_all6,trk_err_all6)), columns = ['FCST_HR','12/00Z'])

trk_err_all7,trk_tim_all7,trk_lat_all7,trk_lon_all7,trk_slp_min_all7,trk_fcst_all7 = [],[],[],[],[],[]
for idx1, val1 in enumerate(tim_obs):
  for idx2, val2 in enumerate(tim_all7):
      if (tim_obs[idx1]==tim_all7[idx2]):
          err=(distance(lat_all7[idx2], lat_obs[idx1], lon_all7[idx2], lon_obs[idx1]))*0.54
          trk_err_all7.append(err)
          trk_tim_all7.append(tim_all7[idx2])
          trk_lat_all7.append(lat_all7[idx2])
          trk_lon_all7.append(lon_all7[idx2])
          trk_slp_min_all7.append(slp_min_all7[idx2])
          trk_fcst_all7.append(fcst_all7[idx2])
dft8 = pd.DataFrame((zip(trk_fcst_all7,trk_err_all7)), columns = ['FCST_HR','13/00Z'])


summarydf = pd.concat([dft1,dft2['07/00Z'],dft3['08/00Z'],dft4['09/00Z'],dft5['10/00Z'],dft6['11/00Z'],dft7['12/00Z'],dft8['13/00Z']], axis=1)
print(summarydf)


#sys.exit()
#----------------------------------------
#PLOTTING
#----------------------------------------
wlon,elon,nlat,slat = -40,-75.,10.,45.

#borders = cfeature.NaturalEarthFeature(category='cultural',name='admin_1_states_provinces_lakes_shp',scale= '50m',facecolor='none',edgecolor='gray')

#fig = plt.figure(figsize=(12, 9))
fig = plt.figure(figsize=(10, 12))
map_projection = ccrs.PlateCarree()
data_transform = ccrs.PlateCarree()

ax = plt.axes(projection=map_projection)
ax.stock_img()
#ax.add_feature(cfeature.LAND, zorder=100, edgecolor='k')
ax.set_extent(((wlon-0.01),(elon+0.01),(slat-0.01),(nlat+0.01)), crs=ccrs.PlateCarree())
ax.coastlines(resolution='50m',              linewidth=0.5)
#ax.add_feature(borders, facecolor='#e0e0e0', linewidth=0.5)


#ax.plot([lon_obs], [lat_obs], 'r*', transform=data_transform,color="black", markersize=8)
#ax.plot([lon_all], [lat_all], 'r*', transform=data_transform,color="green", markersize=8)
#ax.plot([lon_all1], [lat_all1], 'r*', transform=data_transform,color="blue", markersize=8)
#ax.plot([lon_all2], [lat_all2], 'r*', transform=data_transform,color="dodgerblue", markersize=8)
#ax.plot([lon_all3], [lat_all3], 'r*', transform=data_transform,color="royalblue", markersize=8)
#ax.plot([lon_all4], [lat_all4], 'r*', transform=data_transform,color="skyblue", markersize=8)


#for i,j,k in zip(lat_all,lon_all,fcst_all):
#    ax.annotate('{0:.0f}'.format(k),xy=(j,i),xytext=(j+0.2,i),color="green",fontsize=8,horizontalalignment='left', verticalalignment='top')

#for i,j,k in zip(lat_all1,lon_all1,fcst_all1):
#    ax.annotate('{0:.0f}'.format(k),xy=(j,i),xytext=(j+0.2,i),color="blue",fontsize=8,horizontalalignment='left', verticalalignment='top')

#for i,j,k in zip(lat_all2,lon_all2,fcst_all2):
#    ax.annotate('{0:.0f}'.format(k),xy=(j,i),xytext=(j+0.2,i),color="cyan",fontsize=8,horizontalalignment='left', verticalalignment='top')

#for i,j,k in zip(lat_all3,lon_all3,fcst_all3):
#    ax.annotate('{0:.0f}'.format(k),xy=(j,i),xytext=(j+0.2,i),color="teal",fontsize=8,horizontalalignment='left', verticalalignment='top')

ax.set_title('TC Track (Nautical Miles): Lee Atln 2023')

p1, = ax.plot(lon_obs,lat_obs, label="TC Vitals",transform=data_transform,color="black")
p2, = ax.plot(lon_all,lat_all, label="Fcst Init: 06/00Z",transform=data_transform,color="green")
p3, = ax.plot(lon_all1,lat_all1, label="Fcst Init: 07/00Z",transform=data_transform,color="blue")
p4, = ax.plot(lon_all2,lat_all2, label="Fcst Init: 08/00Z",transform=data_transform,color="dodgerblue")
p5, = ax.plot(lon_all3,lat_all3, label="Fcst Init: 09/00Z",transform=data_transform,color="royalblue")
p6, = ax.plot(lon_all4,lat_all4, label="Fcst Init: 10/00Z",transform=data_transform,color="skyblue")
p7, = ax.plot(lon_all5,lat_all5,label="Fcst Init: 11/00Z", transform=data_transform,color="green",linestyle="dashed")
p8, = ax.plot(lon_all6,lat_all6,label="Fcst Init: 12/00Z", transform=data_transform,color="blue",linestyle="dashed")
p9, = ax.plot(lon_all7,lat_all7,label="Fcst Init: 13/00Z", transform=data_transform,color="skyblue",linestyle="dashed")

#ax.legend(handles=[p1,p2,p3,p4,p5],prop={"size":6},ncol=2,bbox_to_anchor=(.85, -0.15),fancybox=True)
ax.legend(handles=[p1,p2,p3,p4,p5,p6,p7,p8,p9],prop={"size":8},ncol=2)
#ax.legend(handles=[p1,p2,p3,p4,p5,p6],prop={"size":10})

gl = ax.gridlines(draw_labels=True)
gl.xlabels_top = False
gl.ylabels_left = False
gl.xformatter = LONGITUDE_FORMATTER
gl.yformatter = LATITUDE_FORMATTER

plt.savefig('TCLee_table_2023_01.png')
plt.show()
sys.exit()
#-------------
#TABLE
#-------------
#plt.table(cellText=summarydf.values,colWidths = [1]*len(summarydf.columns),colLabels=summarydf.columns,cellLoc = 'center', rowLoc = 'center',loc='bottom', bbox=[0.,-.5,1.0, .4])
# bbox[first coordinate is a shift on the x-axis, second coordinate is a gap between plot and text box (table in your case), third coordinate is a width of the text box, fourth coordinate is a height of text box]
summarydf.update(summarydf[['FCST_HR','25/00Z','26/00Z','27/00Z','28/00Z']].applymap('{:,.0f}'.format))
thetable = plt.table(cellText=summarydf.values,colWidths = [0.1]*6,colLabels=("FCST_HR","25/00Z","26/00Z","27/00Z","28/00Z"),cellLoc = 'center', rowLoc = 'center',loc='bottom', bbox=[0.25, -1.55, 0.5, 1.37])
plt.subplots_adjust(left=0.2, bottom=0.5)
#thetable.auto_set_font_size(False)
thetable.set_fontsize(12)
thetable.scale(2,8)
## change cell properties
#plt.savefig('TCHilary_table_2023_01.png')
plt.show()




sys.exit()







